{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T13:48:11.085055Z",
     "iopub.status.busy": "2025-01-22T13:48:11.084788Z",
     "iopub.status.idle": "2025-01-22T13:48:12.531827Z",
     "shell.execute_reply": "2025-01-22T13:48:12.531035Z",
     "shell.execute_reply.started": "2025-01-22T13:48:11.084995Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_path = \"/kaggle/input/flickr2k/Flickr2K\"\n",
    "\n",
    "# Output path for processed data\n",
    "output_path = \"/kaggle/working/processed_data\"\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T13:48:12.534671Z",
     "iopub.status.busy": "2025-01-22T13:48:12.534121Z",
     "iopub.status.idle": "2025-01-22T13:48:12.631289Z",
     "shell.execute_reply": "2025-01-22T13:48:12.630320Z",
     "shell.execute_reply.started": "2025-01-22T13:48:12.534631Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 2650\n",
      "Training images: 2120\n",
      "Validation images: 530\n"
     ]
    }
   ],
   "source": [
    "image_files = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith(\".png\")]\n",
    "\n",
    "#ensure there are images to process\n",
    "if len(image_files) == 0:\n",
    "    raise ValueError(\"No images found in the dataset path.\")\n",
    "\n",
    "#split dataset\n",
    "train_images, val_images = train_test_split(image_files, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(f\"Total images: {len(image_files)}\")\n",
    "print(f\"Training images: {len(train_images)}\")\n",
    "print(f\"Validation images: {len(val_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Preprocess and save images*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T13:48:12.632662Z",
     "iopub.status.busy": "2025-01-22T13:48:12.632310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_and_save(image_paths, save_dir, downscale_factor=2):\n",
    "    # Create directories for HR and LR images\n",
    "    os.makedirs(os.path.join(save_dir, \"HR\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, \"LR\"), exist_ok=True)\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        # Read the image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load {image_path}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Save HR image\n",
    "        hr_path = os.path.join(save_dir, \"HR\", os.path.basename(image_path))\n",
    "        cv2.imwrite(hr_path, img)\n",
    "\n",
    "        # Downsample (bicubic)\n",
    "        height, width, _ = img.shape  # Handle colored images (height, width, channels)\n",
    "        lr = cv2.resize(img, (width // downscale_factor, height // downscale_factor), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Save LR image\n",
    "        lr_path = os.path.join(save_dir, \"LR\", os.path.basename(image_path))\n",
    "        cv2.imwrite(lr_path, lr)\n",
    "\n",
    "# Process training and validation images\n",
    "preprocess_and_save(train_images, os.path.join(output_path, \"train\"))\n",
    "preprocess_and_save(val_images, os.path.join(output_path, \"val\"))\n",
    "\n",
    "# Verify saved images\n",
    "print(\"Processed training LR images:\", len(os.listdir(os.path.join(output_path, \"train/LR\"))))\n",
    "print(\"Processed training HR images:\", len(os.listdir(os.path.join(output_path, \"train/HR\"))))\n",
    "print(\"Processed validation LR images:\", len(os.listdir(os.path.join(output_path, \"val/LR\"))))\n",
    "print(\"Processed validation HR images:\", len(os.listdir(os.path.join(output_path, \"val/HR\"))))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2850129,
     "sourceId": 4914529,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
